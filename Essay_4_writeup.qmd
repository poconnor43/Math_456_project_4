---
title: "Essay_4"
format: pdf
editor: visual
---

# Wine Quality Prediction with KNN

### Authors: Preston O'Connor

### Date: 4/14/2025

## Introduction

```{r}
#libraries given in Step 1 of the slides
# install.packages("class") # For KNN
# install.packages("tidyverse") # For visualization
# install.packages("corrplot") # correlation matrix visualization
# install.packages("ggplot2")# used to view correltation matrix
# install.packages("leaps") #for best subset sum
# install.packages("pROC") # for the ROC analaysys
library(class) # for KNN Implementation 
library(tidyverse) # for visualization
library(corrplot) 
library(ggplot2)
library(caret) # for KNN
library(leaps)
library(pROC)

#loading the data set
data <- read.csv("winequality-red.csv")
#names(wine)
summary(data)
```

## Data Description

### Data source

The dataset used in this project is the Red Wine Quality dataset from the UCI Machine Learning Repository, also available on Kaggle (<https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009>). This dataset was compiled by Paulo Cortez et al. (2009) and is related to red Vinho Verde wine samples from the north of Portugal.

### Data structure and Variables

The dataset contains 1599 observations (rows) and 12 variables (11 numeric input variables and 1 output variable: quality). The variables represent physicochemical attributes of the wine samples:

-   **fixed acidity**: Refers primarily to tartaric acid, which is one of the main acids found naturally in grapes.

-   **volatile acidity**: Measures the amount of acetic acid (vinegar) in the wine.

-   **citric acid**: A natural acid found in small quantities in wine that can add freshness and flavor.

-   **residual sugar**: Represents the amount of sugar remaining after fermentation.

-   **chlorides**: Indicates the amount of salt in the wine, which can affect the taste and preservation.

-   **free sulfur dioxide**: Refers to the part of sulfur dioxide (SO₂) that is not bound to other molecules and is available to act as an antioxidant and antimicrobial agent.

-   **total sulfur dioxide**: Includes both free and bound forms of SO₂.

-   **density**: The density of wine, which is influenced by the sugar and alcohol content.

-   **pH**: Indicates how acidic or basic the wine is.

-   **sulphates**: Sulfate compounds can contribute to the wine’s flavor and preservation.

-   **alcohol**: The percentage of ethanol by volume in the wine.

-   **quality**: This is the response variable, a sensory score assigned by professional tasters ranging from 0 to 10. It reflects the overall quality of the wine sample based on taste, aroma, and balance.

### Data cleaning

```{r}
# Boxplots to detect outliers
par(mfrow = c(2, 3))
for (i in 1:6) {
  boxplot(data[[i]], main = names(data)[i])
}

# Plot remaining 6 variables
par(mfrow = c(2, 3))
for (i in 7:12) {
  boxplot(data[[i]], main = names(data)[i])
}

par(mfrow = c(1, 1))  # Reset

# Function to remove outliers beyond 1.5 * IQR
remove_outliers_IQR <- function(df, column) {
  #df <- df %>% filter(!is.na(df[[column]]))  # Remove missing data
  df <- df %>% filter(!is.na(!!sym(column))) 
  Q1 <- quantile(df[[column]], 0.25, na.rm = T)
  Q3 <- quantile(df[[column]], 0.75, na.rm = T)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  df %>% filter(df[[column]] >= lower_bound & df[[column]] <= upper_bound)
}

# Remove outliers for all relevant columns
data_cleaned <- data
columns <- c("fixed.acidity", "volatile.acidity", "citric.acid", 
             "residual.sugar", "chlorides", "free.sulfur.dioxide", 
             "total.sulfur.dioxide", "density", "pH", 
             "sulphates", "alcohol")

data_cleaned <- data

for (col in columns) {
  data_cleaned <- remove_outliers_IQR(data_cleaned, col)
}

# Summary of the cleaned data
summary(data_cleaned)

# New size of the cleaned dataset
nrow(data_cleaned)
```

The dataset contains 1135 observations (rows) after removing outliers.

### Normalize Data

```{r}
normalize <- function(x) { (x - min(x)) / (max(x) - min(x)) }
 
data_norm <- as.data.frame(lapply(data_cleaned[, 1:11], normalize))
head(data_norm)
```

### Data visualization

```{r}
# Reshape data to long format
wine_long <- pivot_longer(data_norm, cols = 1:11, names_to = "variable", values_to = "value")

# Create faceted histogram plot
ggplot(wine_long, aes(x = value)) +
  geom_histogram(bins = 20, fill = "steelblue", color = "white") +
  facet_wrap(~variable, scales = "free", ncol = 3) +
  theme_minimal() +
  labs(title = "Histograms of Wine Features", x = "", y = "Count")
```

### Correlation matrix

```{r}
# Compute correlation matrix for numeric input variables
cor_matrix <- cor(data_norm[, 1:11])  # Exclude 'quality' if you're only interested in inputs
print(round(cor_matrix, 2))      # Round for readability

corrplot(cor_matrix, method = "color", type = "upper",
         tl.col = "black", tl.srt = 45,
         addCoef.col = "black", number.cex = 0.7,
         col = colorRampPalette(c("blue", "white", "red"))(200))
```

## Analysis

### Best Subset 

```{r}
data_combined <- cbind(data_norm, quality = data_cleaned$quality)
 nrow(data_norm)
 
# due to 2 instances of the value of qaulity 3 remove the data
data_combined <- data_combined %>% 
  filter(quality !=3)
 # remove the data with the two points of classification as three
 
 

nrow(data_combined)
```

## Analysis

### Train and Test Split with the optimized K

```{r}
# First Implement the Seed and split the Training and Testing Data
set.seed(12)
#selected_cols <- c(2,10,11) # this received 61.25% with k =20
#selected_cols <- c(2,3,4,5, 7, 8, 9,10,11) # this received 61.87% with k = 31
index <- sample(1:nrow(data_combined), 0.8 * nrow(data_combined))

train_data <- data_combined[index, 1:11]   # Features: columns 1 to 11
test_data <- data_combined[-index, 1:11]

cat("Number of training samples:", nrow(train_data), "\n")
cat("Number of testing samples:", nrow(test_data), "\n")

train_labels <- data_combined[index, 12]   # Target: column 12
test_labels <- data_combined[-index, 12]

# The numbers are treated as categorical not to calculate the average from
train_labels <- as.factor(train_labels)
test_labels <- as.factor(test_labels)


# Step 3: Train KNN with k = 2-60
accuracy_list <- c()

for (k in 2:60) {
  knn_pred <- knn(train = train_data, test = test_data, cl = train_labels, k = k)
  acc <- mean(knn_pred == test_labels)
  accuracy_list <- c(accuracy_list, acc)
}

# Find the best k
best_k <- k_values[which.max(accuracy_list)]

cat("The Best k:", best_k, "\n")
cat("The Best Accuracy:", round(best_acc, 4), "\n")

# Optional: Final model with best k
final_knn <- knn(train = train_data, test = test_data, cl = train_labels, k = best_k)

```

## Model Evaluation

### The K is optimized

```{r}
k_values <- 1:60
accuracies <- sapply(k_values, function(k) {
pred <- knn(train_data, test_data, cl = train_labels, k = k)
mean(pred == test_labels)
})
# Plot accuracy vs. K
plot(k_values, accuracies, type = "b", col = "blue", pch = 19,
xlab = "K", ylab = "Accuracy", main = "Optimal K Selection")
```

-   The plot illustrates that although the highest accuracy is achieved at k equal to 1, this is generally ignored in KNN as it is noise-sensitive and prone to overfitting. A strong local maximum in accuracy appears around k equal to 10, suggesting this is a more plausible choice. After this point, as k increases, accuracy gradually declines, indicating that larger neighborhoods reduce the model’s predictive accuracy. Therefore, intermediate values of k (between 5 and 15) offer a good compromise between capturing local structure and achieving generalization.

### The Confusion Matrix

```{r}
conf_matrix <- table(Predicted = final_knn, Actual = test_labels)


conf_matrix_df <- as.data.frame(as.table(conf_matrix))

ggplot(data = conf_matrix_df, aes(x = Predicted, y = Actual, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), color = "black", size = 6) +
  scale_fill_gradient(low = "white", high = "blue") +
  theme_minimal() +
  labs(x = "Predicted", y = "Actual", fill = "Frequency") +
  theme(axis.text.x = element_text(hjust = 1))

```

-   Based on the confusion matrix, the KNN model is moderately accurate with the majority of the correct predictions clustered around classes 5 and 6. Class 6 has the maximum true positive value (61), indicating that the model is most confident in classifying this class correctly; however, there is a large misclassification between neighboring classes: a majority of class 5 wines are forecast as class 6 (64), and the class 6 wines are largely forecast as 5 (24) or 7 (6). Class 7 forecasts are everywhere, and the model performs very badly with classes 4 and 8, correctly classifying none within these groups. This means that the model is most powerful at detecting common, central classes, but less sensitive to less common or edge-case classes. Overall, the model gives general trends regarding wine quality, but may be assisted by algorithms that provide improved performance on underrepresented classes.

### Multiple of Class Precision, Recall, and F1 Score

```{r}
conf_matrix <- confusionMatrix(final_knn, test_labels)
# print(conf_matrix) # for debugging purposes

cm_by_class <- conf_matrix$byClass

if (is.null(dim(cm_by_class))) {
  precision <- cm_by_class["Pos Pred Value"]
  recall <- cm_by_class["Sensitivity"]
  f1 <- 2 * (precision * recall) / (precision + recall)
  metrics_df <- data.frame(
    Class = levels(test_labels),
    Precision = round(precision, 3),
    Recall = round(recall, 3),
    F1_Score = round(f1, 3)
  )
} else {
  precision <- cm_by_class[, "Pos Pred Value"]
  recall <- cm_by_class[, "Sensitivity"]
  f1 <- 2 * (precision * recall) / (precision + recall)
  metrics_df <- data.frame(
    Class = rownames(cm_by_class),
    Precision = round(precision, 3),
    Recall = round(recall, 3),
    F1_Score = round(f1, 3)
  )
}

print(metrics_df)

```

-   Class 4: The model did not predict any wines as quality 4. Precision and recall are both 0, indicating that it completely missed this class.

-    Class 5: For class 5, the model is most accurate, with 65.3% precision and 68.1% recall, meaning it correctly identifies most wines with this quality.

-   Class 6: Class 6 predictions are good with precision 56.5% and recall 67%, indicating moderate accuracy and good coverage.

-   Class 7: The model performs badly on class 7 with only 50% accuracy and 29.4% recall, thus missing most of the true class 7 wines.

-   Class 8: The model doesn't predict class 8 at all. Both precision and recall are 0, which means it completely fails to predict this class.

-   delete this point is so i know i submitted the right draft on 4/11

## Conclusion & Summary

## Sources

-   Source 1

-   Source 2

-   Kaggle data set
